{
  "hash": "ff84535ab3c8b5da9673ab8b004f454d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntopic: \"Predictive Modeling in `R`\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n# {{< meta topic >}}\n\n## Where are We?\n\n::: {style=\"font-size: 85%;\"}\n- `R` Basics\n- Data Visualization\n- [`R` Programming]{color=\"blue\"}\n  - [Statistical Analysis]{color=\"blue\"}\n- Tidy Data Manipulation\n- `python` Basics\n- Web Scraping with `python`\n\n:::\n\n\n## Goals for this Video\n\nIn this video: \n\n::: incremental\n\n- What is Predictive Modeling?\n- The `tidymodels` Ecosystem\n\n:::\n\n\n## tidymodels\n\nStrength of `R`: \n \n- Thousands of authors contributing packages to CRAN\n\n. . . \n\nWeakness of `R`: \n\n- Thousands of authors contributing *slightly incompatible* packages to CRAN\n\n. . . \n\nNo two modeling packages have _exactly_ the same API. Makes \nchanging between interfaces cumbersome\n\n## tidymodels\n\n`tidymodels` attemps to provide a _uniform_ interface\nto a wide variety of _predictive_ Machine Learning tools\n\nAdvantages: \n\n- Easy to swap out different algorithms to find the best\n\nDisadvantages: \n\n- Harder to take advantage of the strengths of each approach\n\n## ML vs Statistical Pipelines\n\nStatistics / Data Science: \n\n- Find the model that _fits_ the data best\n- Model should capture all important data features\n- _Interpretability_ \n- History: Grounded in lab sciences where experiments are\n  expensive and data is limited \n  \n## ML vs Statistical Pipelines\n\nMachine Learning: \n\n- Find the model that _predicts_ the data best\n- No \"perfect\" model - just the best one we've found so far\n- Black-box techniques are great, _if effective_\n- History: Silicon Valley \"at scale\"\n\nValidation based on _of-of-sample_ or _test_ predictions\n\n## Validating Predictive Power\n\nHow to check whether a model _predicts_ well?\n\n. . . \n\nNeed more data! But where to get more data? \n\n- Actually get more data (hard, expensive, slow)\n- Split data into parts - test/training split\n- Cross-Validation\n- Resampling\n\n. . . \n\nToday, we'll primarily use a combination: **Test/Train** split & **Cross-Validation**!\n\n## Cross-Validation\n\n![](https://scikit-learn.org/1.5/_images/grid_search_cross_validation.png)\n\nCross-Validation is done on the *estimator*, not the fitted algorithm\n\n## tidymodels\n\n`tidymodels` workflow: \n\n- Initial Split\n- Pre-Process\n- Fit (*many*) models\n- Select best\n- Refit\n- Test Set Assessment\n\n`tidymodels` is _very_ punny, so a bit hard to tell which step is which...\n\n## Acquire Data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels); library(readr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.0     \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n```\n\n\n:::\n\n```{.r .cell-code}\nhotels <- \n  read_csv(\"https://tidymodels.org/start/case-study/hotels.csv\") |>\n  mutate(across(where(is.character), as.factor))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 50000 Columns: 23\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (11): hotel, children, meal, country, market_segment, distribution_chan...\ndbl  (11): lead_time, stays_in_weekend_nights, stays_in_week_nights, adults,...\ndate  (1): arrival_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(hotels)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 50,000\nColumns: 23\n$ hotel                          <fct> City_Hotel, City_Hotel, Resort_Hotel, R…\n$ lead_time                      <dbl> 217, 2, 95, 143, 136, 67, 47, 56, 80, 6…\n$ stays_in_weekend_nights        <dbl> 1, 0, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1, …\n$ stays_in_week_nights           <dbl> 3, 1, 5, 6, 4, 2, 2, 3, 4, 2, 2, 1, 2, …\n$ adults                         <dbl> 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, …\n$ children                       <fct> none, none, none, none, none, none, chi…\n$ meal                           <fct> BB, BB, BB, HB, HB, SC, BB, BB, BB, BB,…\n$ country                        <fct> DEU, PRT, GBR, ROU, PRT, GBR, ESP, ESP,…\n$ market_segment                 <fct> Offline_TA/TO, Direct, Online_TA, Onlin…\n$ distribution_channel           <fct> TA/TO, Direct, TA/TO, TA/TO, Direct, TA…\n$ is_repeated_guest              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ previous_cancellations         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ previous_bookings_not_canceled <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ reserved_room_type             <fct> A, D, A, A, F, A, C, B, D, A, A, D, A, …\n$ assigned_room_type             <fct> A, K, A, A, F, A, C, A, D, A, D, D, A, …\n$ booking_changes                <dbl> 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ deposit_type                   <fct> No_Deposit, No_Deposit, No_Deposit, No_…\n$ days_in_waiting_list           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ customer_type                  <fct> Transient-Party, Transient, Transient, …\n$ average_daily_rate             <dbl> 80.75, 170.00, 8.00, 81.00, 157.60, 49.…\n$ required_car_parking_spaces    <fct> none, none, none, none, none, none, non…\n$ total_of_special_requests      <dbl> 1, 3, 2, 1, 4, 1, 1, 1, 1, 1, 0, 1, 0, …\n$ arrival_date                   <date> 2016-09-01, 2017-08-25, 2016-11-19, 20…\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Initial Split\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stratified sampling to ensure balance\nsplits      <- initial_split(hotels, \n                             strata = children)\n\nhotel_train <- training(splits)\nhotel_test  <- testing(splits)\n\nhotel_train\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 37,500 × 23\n   hotel   lead_time stays_in_weekend_nig…¹ stays_in_week_nights adults children\n   <fct>       <dbl>                  <dbl>                <dbl>  <dbl> <fct>   \n 1 City_H…       217                      1                    3      2 none    \n 2 City_H…         2                      0                    1      2 none    \n 3 Resort…        95                      2                    5      2 none    \n 4 City_H…        67                      2                    2      2 none    \n 5 Resort…        47                      0                    2      2 children\n 6 City_H…        56                      0                    3      0 children\n 7 City_H…        80                      0                    4      2 none    \n 8 City_H…         6                      2                    2      2 children\n 9 City_H…        27                      0                    1      1 none    \n10 Resort…        46                      0                    2      2 none    \n# ℹ 37,490 more rows\n# ℹ abbreviated name: ¹​stays_in_weekend_nights\n# ℹ 17 more variables: meal <fct>, country <fct>, market_segment <fct>,\n#   distribution_channel <fct>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>, previous_bookings_not_canceled <dbl>,\n#   reserved_room_type <fct>, assigned_room_type <fct>, booking_changes <dbl>,\n#   deposit_type <fct>, days_in_waiting_list <dbl>, customer_type <fct>, …\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Pre-Process {.scrollable}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(recipes)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nholidays <- c(\"AllSouls\", \"AshWednesday\", \"ChristmasEve\", \"Easter\", \n              \"ChristmasDay\", \"GoodFriday\", \"NewYearsDay\", \"PalmSunday\")\n\nlr_recipe <- \n  recipe(children ~ ., data = hotels) |> \n  step_date(arrival_date) |> \n  step_holiday(arrival_date, holidays = holidays) |> \n  step_rm(arrival_date) |> \n  step_dummy(all_nominal_predictors()) |> \n  step_zv(all_predictors()) |> \n  step_normalize(all_predictors())\n\nlr_recipe\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:    1\npredictor: 22\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Date features from: arrival_date\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Holiday features from: arrival_date\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Variables removed: arrival_date\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Dummy variables from: all_nominal_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Zero variance filter on: all_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Centering and scaling for: all_predictors()\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Fit Models\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_model <- \n  logistic_reg(penalty = tune(), mixture = 1) |> \n  set_engine(\"glmnet\")\n\nlr_model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Select Best\n\nFind a _grid_ of parameters \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_reg_grid <- data.frame(penalty = 10^seq(-4, -1, length.out = 30))\n```\n:::\n\n\n\n\n\n\nPerform CV splits: \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_folds <- vfold_cv(hotel_train, v = 5)\n```\n:::\n\n\n\n\n\n\n## Select Best\n\nDefine a *workflow*: \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_workflow <-  \n  workflow() |> \n  add_model(lr_model) |> \n  add_recipe(lr_recipe)\n```\n:::\n\n\n\n\n\n\nFit workflow to a grid of parameters: \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_results <- \n  lr_workflow |> \n  tune_grid(grid = lr_reg_grid,\n            control = control_grid(save_pred = TRUE, \n                                   save_workflow=TRUE),\n            resamples = lr_folds,\n            metrics = metric_set(roc_auc))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ The workflow being saved contains a recipe, which is 6.79 Mb in ℹ memory. If\nthis was not intentional, please set the control setting ℹ `save_workflow =\nFALSE`.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Select Best\n\nVisual examination\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_results |> \n  collect_metrics() |> \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() + \n  ylab(\"Area under the ROC Curve\") +\n  scale_x_log10(labels = scales::label_number())\n```\n\n::: {.cell-output-display}\n![](09b_modeling_II_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n## Select Best\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_results |> show_best()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in show_best(lr_results): No value of `metric` was given; \"roc_auc\"\nwill be used.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00137  roc_auc binary     0.877     5 0.00296 Preprocessor1_Model12\n2 0.00174  roc_auc binary     0.877     5 0.00310 Preprocessor1_Model13\n3 0.00108  roc_auc binary     0.876     5 0.00285 Preprocessor1_Model11\n4 0.00221  roc_auc binary     0.876     5 0.00326 Preprocessor1_Model14\n5 0.000853 roc_auc binary     0.876     5 0.00280 Preprocessor1_Model10\n```\n\n\n:::\n\n```{.r .cell-code}\nlr_best <- lr_results |> select_best()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in select_best(lr_results): No value of `metric` was given; \"roc_auc\"\nwill be used.\n```\n\n\n:::\n\n```{.r .cell-code}\nlr_best\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  penalty .config              \n    <dbl> <chr>                \n1 0.00137 Preprocessor1_Model12\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Refit Best Model\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_best_fit <- lr_results |> fit_best()\nlr_best_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_date()\n• step_holiday()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"binomial\",      alpha = ~1) \n\n    Df  %Dev   Lambda\n1    0  0.00 0.078680\n2    1  2.44 0.071690\n3    2  5.20 0.065320\n4    3  7.59 0.059520\n5    3  9.78 0.054230\n6    4 12.20 0.049410\n7    4 13.95 0.045020\n8    5 15.58 0.041020\n9    5 17.01 0.037380\n10   5 18.12 0.034060\n11   5 19.01 0.031030\n12   6 19.98 0.028270\n13   6 20.86 0.025760\n14   7 21.58 0.023470\n15   8 22.23 0.021390\n16   8 23.01 0.019490\n17   8 23.61 0.017760\n18   9 24.16 0.016180\n19  10 24.73 0.014740\n20  10 25.19 0.013430\n21  11 25.61 0.012240\n22  13 26.00 0.011150\n23  13 26.37 0.010160\n24  14 26.70 0.009259\n25  17 27.04 0.008436\n26  20 27.43 0.007687\n27  22 27.91 0.007004\n28  24 28.39 0.006382\n29  27 28.87 0.005815\n30  28 29.32 0.005298\n31  32 29.72 0.004828\n32  38 30.12 0.004399\n33  41 30.59 0.004008\n34  45 31.03 0.003652\n35  45 31.41 0.003327\n36  49 31.76 0.003032\n37  50 32.06 0.002762\n38  55 32.33 0.002517\n39  59 32.58 0.002293\n40  63 32.80 0.002090\n41  69 33.01 0.001904\n42  70 33.19 0.001735\n43  74 33.35 0.001581\n44  76 33.48 0.001440\n45  80 33.60 0.001312\n46  84 33.71 0.001196\n\n...\nand 36 more lines.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Test Set Assessment\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(lr_best_fit, hotel_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12,500 × 1\n   .pred_class\n   <fct>      \n 1 none       \n 2 children   \n 3 none       \n 4 none       \n 5 none       \n 6 none       \n 7 none       \n 8 none       \n 9 none       \n10 none       \n# ℹ 12,490 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(lr_best_fit, hotel_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12,500 × 26\n   .pred_class .pred_children .pred_none hotel  lead_time stays_in_weekend_nig…¹\n   <fct>                <dbl>      <dbl> <fct>      <dbl>                  <dbl>\n 1 none               0.0252       0.975 Resor…       143                      2\n 2 children           0.753        0.247 Resor…       136                      1\n 3 none               0.0550       0.945 City_…       130                      1\n 4 none               0.00317      0.997 Resor…        16                      1\n 5 none               0.0350       0.965 City_…        22                      1\n 6 none               0.00668      0.993 Resor…        96                      4\n 7 none               0.0204       0.980 City_…       134                      0\n 8 none               0.0904       0.910 City_…        39                      0\n 9 none               0.0483       0.952 City_…         5                      2\n10 none               0.0236       0.976 City_…        43                      1\n# ℹ 12,490 more rows\n# ℹ abbreviated name: ¹​stays_in_weekend_nights\n# ℹ 20 more variables: stays_in_week_nights <dbl>, adults <dbl>,\n#   children <fct>, meal <fct>, country <fct>, market_segment <fct>,\n#   distribution_channel <fct>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>, previous_bookings_not_canceled <dbl>,\n#   reserved_room_type <fct>, assigned_room_type <fct>, …\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## tidymodels tools\n\n- Feature Importance Scores\n- Model Stacking\n- Probabilistic Predictions\n- Uncertainty Bounds (Conformal Inference)\n- Multilevel (Mixed-Effect) Models\n- Fairness Audits\n\n\n## Looking Ahead\n\nApplications to course project: \n\n::: {.incremental}\n\n- Two variables are *statistically independent* if\n  one cannot be used to predict the other\n- Many questions take the form \"Is $X$ related to $Y$?\"\n- Build a *model* to predict $Y$ from $X$\n  - If model doesn't use $X$ (small coefficient or importance), unlikely to be related\n  - Move beyond simple linear correlation\n- Also consider *occlusion* studies\n\n:::\n\n## Learning More\n\nFor more: \n\n- Modeling - future STA and CIS classes\n- `tidymodels` - [Case Study](https://www.tidymodels.org/start/case-study/)\n\n\n. . . \n\nTo see more worked examples of predictive models, check out the \n[`tidymodels` Gallery](https://www.tidymodels.org/learn/)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}